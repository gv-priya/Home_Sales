{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "import pyspark\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "spark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "T_8og1-Kigtu",
        "outputId": "b48e420f-f8b9-461d-b17a-2000c8cff215"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,353 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,998 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,848 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,961 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,569 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [737 kB]\n",
            "Fetched 9,809 kB in 3s (3,819 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "38 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=0933bdadf4e37c31bb367ac63787bb265dc3cae298a8fe9dd0e936437f2b6dd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c88e9b22e90>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://bf7b13851a8c:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "EOOYPPQyINqm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "from pyspark.sql import SparkSession\n",
        "import time\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ],
      "metadata": {
        "id": "zipKZhVhIYO2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Read in the AWS S3 bucket into a DataFrame.\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n"
      ],
      "metadata": {
        "id": "-MZ_JfO6J2cq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create a temporary view of the DataFrame.\n",
        "spark.sparkContext.addFile(url)\n",
        "df=spark.read.csv(SparkFiles.get(\"home_sales_revised.csv\"), sep=\",\",header=True, inferSchema = True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGwfuPJoJ9Zm",
        "outputId": "41ea9043-0c0b-4c55-b66e-0403fa535283"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
            "|                  id|      date|date_built| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|\n",
            "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
            "|f8a53099-ba1c-47d...|2022-04-08|      2016|936923|       4|        3|       3167|   11733|     2|         1|  76|\n",
            "|7530a2d8-1ae3-451...|2021-06-13|      2013|379628|       2|        2|       2235|   14384|     1|         0|  23|\n",
            "|43de979c-0bf0-4c9...|2019-04-12|      2014|417866|       2|        2|       2127|   10575|     2|         0|   0|\n",
            "|b672c137-b88c-48b...|2019-10-16|      2016|239895|       2|        2|       1631|   11149|     2|         0|   0|\n",
            "|e0726d4d-d595-407...|2022-01-08|      2017|424418|       3|        2|       2249|   13878|     2|         0|   4|\n",
            "|5aa00529-0533-46b...|2019-01-30|      2017|218712|       2|        3|       1965|   14375|     2|         0|   7|\n",
            "|131492a1-72e2-4a8...|2020-02-08|      2017|419199|       2|        3|       2062|    8876|     2|         0|   6|\n",
            "|8d54a71b-c520-44e...|2019-07-21|      2010|323956|       2|        3|       1506|   11816|     1|         0|  25|\n",
            "|e81aacfe-17fe-46b...|2020-06-16|      2016|181925|       3|        3|       2137|   11709|     2|         0|  22|\n",
            "|2ed8d509-7372-46d...|2021-08-06|      2015|258710|       3|        3|       1918|    9666|     1|         0|  25|\n",
            "|f876d86f-3c9f-42b...|2019-02-27|      2011|167864|       3|        3|       2471|   13924|     2|         0|  15|\n",
            "|0a2bd445-8508-4d8...|2021-12-30|      2014|337527|       2|        3|       1926|   12556|     1|         0|  23|\n",
            "|941bad30-eb49-4a7...|2020-05-09|      2015|229896|       3|        3|       2197|    8641|     1|         0|   3|\n",
            "|dd61eb34-6589-4c0...|2021-07-25|      2016|210247|       3|        2|       1672|   11986|     2|         0|  28|\n",
            "|f1e4cef7-d151-439...|2019-02-01|      2011|398667|       2|        3|       2331|   11356|     1|         0|   7|\n",
            "|ea620c7b-c2f7-4c6...|2021-05-31|      2011|437958|       3|        3|       2356|   11052|     1|         0|  26|\n",
            "|f233cb41-6f33-4b0...|2021-07-18|      2016|437375|       4|        3|       1704|   11721|     2|         0|  34|\n",
            "|c797ca12-52cd-4b1...|2019-06-08|      2015|288650|       2|        3|       2100|   10419|     2|         0|   7|\n",
            "|0cfe57f3-28c2-472...|2019-10-04|      2015|308313|       3|        3|       1960|    9453|     2|         0|   2|\n",
            "|4566cd2a-ac6e-435...|2019-07-15|      2016|177541|       3|        3|       2130|   10517|     2|         0|  25|\n",
            "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()\n",
        "from pyspark.sql.types import IntegerType, DoubleType\n",
        "from pyspark.sql import functions as F\n",
        "df = df.withColumn(\"price\", df[\"price\"].cast(IntegerType()))\n",
        "df = df.withColumn(\"bedrooms\", df[\"bedrooms\"].cast(IntegerType()))\n",
        "df = df.withColumn(\"date\", F.to_date(df[\"date\"]))\n",
        "df.select(F.max('date')).show()\n",
        "df.select(F.min('date')).show()\n",
        "date1 =('2019-01-01', '2019-12-31')\n",
        "date2 = ('2020-01-01', '2020-12-30')\n",
        "date3=('2021-01-01', '2021-01-30')\n",
        "date4=('2022-01-01', '2022-06-14')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qP_ZsA_NHJG",
        "outputId": "45ea7f88-90c3-4540-b5a2-6e51046a8c65"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- date: date (nullable = true)\n",
            " |-- date_built: integer (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            " |-- bedrooms: integer (nullable = true)\n",
            " |-- bathrooms: integer (nullable = true)\n",
            " |-- sqft_living: integer (nullable = true)\n",
            " |-- sqft_lot: integer (nullable = true)\n",
            " |-- floors: integer (nullable = true)\n",
            " |-- waterfront: integer (nullable = true)\n",
            " |-- view: integer (nullable = true)\n",
            "\n",
            "+----------+\n",
            "| max(date)|\n",
            "+----------+\n",
            "|2022-06-14|\n",
            "+----------+\n",
            "\n",
            "+----------+\n",
            "| min(date)|\n",
            "+----------+\n",
            "|2019-01-01|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import round\n",
        "from pyspark.sql.functions import year\n",
        "df.select(year(df[\"date\"]))\n",
        "df=df.withColumn(\"year\", year(df['date']))\n",
        "# 3. What is the average price for a four bedroom house sold per year, rounded to two decimal places?\n",
        "year_price_4bedroom =df.select([\"price\", \"date\",\"bedrooms\"]).where(df.bedrooms == 4)\n",
        "new2019df=df.groupBy(df.date.between('2019-01-01', '2019-12-31').alias(\"Year=2019\")).agg(round(F.avg(F.when(df.bedrooms == F.lit('4'), F.col(\"price\"))),2).alias(\"average_price\")).show(truncate=False)\n",
        "new2020df=df.groupBy(df.year == F.lit('2020')).agg(round(F.avg(F.when(df.bedrooms == F.lit('4'), F.col(\"price\"))), 2).alias(\"average_price\")).show()\n",
        "new2021df=df.groupBy(df.year == F.lit('2021')).agg(round(F.avg(F.when(df.bedrooms == F.lit('4'), F.col(\"price\"))), 2).alias(\"average_price\")).show()\n",
        "new2022df=df.groupBy(df.year == F.lit('2022')).agg(round(F.avg(F.when(df.bedrooms == F.lit('4'), F.col(\"price\"))), 2).alias(\"average_price\")).show()\n",
        "new2019df\n",
        "new2020df\n",
        "new2021df\n",
        "new2022df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qVmoWqlNzTd",
        "outputId": "c9a68f44-098f-4e05-822c-d1d1faf9f441"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+\n",
            "|Year=2019|average_price|\n",
            "+---------+-------------+\n",
            "|true     |300263.7     |\n",
            "|false    |299417.37    |\n",
            "+---------+-------------+\n",
            "\n",
            "+-------------+-------------+\n",
            "|(year = 2020)|average_price|\n",
            "+-------------+-------------+\n",
            "|         true|    298353.78|\n",
            "|        false|    300197.81|\n",
            "+-------------+-------------+\n",
            "\n",
            "+-------------+-------------+\n",
            "|(year = 2021)|average_price|\n",
            "+-------------+-------------+\n",
            "|         true|    301819.44|\n",
            "|        false|    298769.09|\n",
            "+-------------+-------------+\n",
            "\n",
            "+-------------+-------------+\n",
            "|(year = 2022)|average_price|\n",
            "+-------------+-------------+\n",
            "|         true|    296363.88|\n",
            "|        false|    300147.68|\n",
            "+-------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_# 4. What is the average price of a home for each year the home was built,\n",
        "# that have 3 bedrooms and 3 bathrooms, rounded to two decimal places?\n",
        "bath_bedrooms_avgprice = df.groupBy(df.date_built, F.when(df.bedrooms== 3, 1).when(df.bathrooms==3, 1).otherwise(0).alias(\"3Bedrooms&bathrooms\")).agg(round(F.avg(df.price),2).alias(\"average_price\"))\n",
        "bath_bedrooms_avgprice.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_jx4FuLlWl_",
        "outputId": "314064d4-a399-4512-f2c5-870ebe3c5315"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------+-------------+\n",
            "|date_built|3Bedrooms&bathrooms|average_price|\n",
            "+----------+-------------------+-------------+\n",
            "|      2012|                  0|    338716.63|\n",
            "|      2011|                  0|     339922.0|\n",
            "|      2014|                  0|    341867.73|\n",
            "|      2017|                  0|    342863.35|\n",
            "|      2013|                  0|    338539.26|\n",
            "|      2010|                  0|    330051.36|\n",
            "|      2014|                  1|    302781.87|\n",
            "|      2015|                  0|     339105.1|\n",
            "|      2016|                  0|    338365.96|\n",
            "|      2016|                  1|    303311.05|\n",
            "|      2012|                  1|    300270.37|\n",
            "|      2013|                  1|    306642.66|\n",
            "|      2015|                  1|    302997.92|\n",
            "|      2011|                  1|    302751.77|\n",
            "|      2010|                  1|    299133.19|\n",
            "|      2017|                  1|    301733.01|\n",
            "+----------+-------------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. What is the average price of a home for each year the home was built,\n",
        "# that have 3 bedrooms, 3 bathrooms, with two floors,\n",
        "# and are greater than or equal to 2,000 square feet, rounded to two decimal places?\n",
        "home_sales_df = df.groupBy(df.date_built, F.when(df.bedrooms== 3, 1).when(df.bathrooms==3, 1).otherwise(0).alias(\"3Bedrooms&bathrooms\"),\n",
        "                                    F.when(df.floors == 2, 1).when(df.sqft_living >= 2000, 1).otherwise(0).alias(\"2floors_morethan2000SQFT\")).agg(round(F.avg(df.price),2).alias(\"Average_Price\"))\n",
        "home_sales_df.show()"
      ],
      "metadata": {
        "id": "2lqhiCCumBBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb8c46a-1d39-449a-9862-66082efb0b47"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------+------------------------+-------------+\n",
            "|date_built|3Bedrooms&bathrooms|2floors_morethan2000SQFT|Average_Price|\n",
            "+----------+-------------------+------------------------+-------------+\n",
            "|      2013|                  1|                       0|     285754.7|\n",
            "|      2014|                  1|                       1|    306821.56|\n",
            "|      2010|                  0|                       1|    343016.82|\n",
            "|      2012|                  0|                       1|    354737.58|\n",
            "|      2015|                  1|                       0|    281701.47|\n",
            "|      2016|                  0|                       1|     355089.8|\n",
            "|      2011|                  0|                       0|    291042.71|\n",
            "|      2013|                  0|                       1|    355952.04|\n",
            "|      2016|                  1|                       1|    309764.75|\n",
            "|      2011|                  1|                       1|    308540.15|\n",
            "|      2012|                  1|                       0|    280152.97|\n",
            "|      2015|                  0|                       0|    286512.34|\n",
            "|      2011|                  1|                       0|    283693.54|\n",
            "|      2017|                  1|                       1|    305996.56|\n",
            "|      2014|                  1|                       0|    290291.14|\n",
            "|      2010|                  1|                       1|    302308.07|\n",
            "|      2012|                  1|                       1|    306751.21|\n",
            "|      2014|                  0|                       1|    358803.57|\n",
            "|      2017|                  1|                       0|    288515.98|\n",
            "|      2015|                  0|                       1|    353231.06|\n",
            "+----------+-------------------+------------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. What is the average price of a home per \"view\" rating, rounded to two decimal places,\n",
        "# having an average home price greater than or equal to $350,000? Order by descending view rating.\n",
        "# Although this is a small dataset, determine the run time for this query.\n",
        "start_time = time.time()\n",
        "home_sales_HS = df.groupBy(df.view, F.when(df.bedrooms== 3, 1).when(df.bathrooms==3, 1).otherwise(0).alias(\"3Bedrooms&bathrooms\"),\n",
        "                                    F.when(df.floors == 2, 1).when(df.sqft_living >= 2000, 1).otherwise(0).alias(\"2floors_morethan2000SQFT\")).agg(round(F.avg(df.price),2).alias(\"Average_Price\"))\n",
        "home_sales_HS.orderBy(F.when(home_sales_HS.Average_Price >= 350000, 1).otherwise(0).desc()).show()\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "Schema_homesales = home_sales_HS.schema\n",
        "Schema_homesales\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cngPJlA4p74k",
        "outputId": "4c74c24b-911c-4086-980a-d4ac589e11a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------------+------------------------+-------------+\n",
            "|view|3Bedrooms&bathrooms|2floors_morethan2000SQFT|Average_Price|\n",
            "+----+-------------------+------------------------+-------------+\n",
            "|  83|                  1|                       1|    967777.94|\n",
            "|  60|                  1|                       1|    799710.71|\n",
            "|  76|                  1|                       1|   1013447.44|\n",
            "|  70|                  0|                       1|    715162.21|\n",
            "|  88|                  1|                       1|    916647.93|\n",
            "|  75|                  0|                       1|    1155976.5|\n",
            "|  89|                  1|                       1|     976732.5|\n",
            "|  69|                  1|                       1|    699738.22|\n",
            "|  92|                  1|                       1|    983242.27|\n",
            "|  51|                  1|                       1|    807649.14|\n",
            "|  58|                  1|                       1|    782675.21|\n",
            "|  98|                  0|                       1|   1163281.95|\n",
            "|  98|                  1|                       1|    862039.75|\n",
            "|  59|                  1|                       1|    743560.85|\n",
            "|  55|                  1|                       1|     759954.8|\n",
            "|  96|                  0|                       1|   1054094.52|\n",
            "|  55|                  0|                       1|    780485.42|\n",
            "|  62|                  0|                       1|    724032.89|\n",
            "|  68|                  0|                       1|    719135.38|\n",
            "|  85|                  0|                       1|   1159231.91|\n",
            "+----+-------------------+------------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 1.1037113666534424 seconds ---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('view', IntegerType(), True), StructField('3Bedrooms&bathrooms', IntegerType(), False), StructField('2floors_morethan2000SQFT', IntegerType(), False), StructField('Average_Price', DoubleType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Cache the temporary table home_sales.\n",
        "df.createOrReplaceTempView(\"home_sales\")\n",
        "spark.sql(\"\"\"SELECT * FROM home_sales\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VlGgJVQvodE",
        "outputId": "4f43e08a-491a-4afc-fd94-a9bc798045c6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+----+\n",
            "|                  id|      date|date_built| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|year|\n",
            "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+----+\n",
            "|f8a53099-ba1c-47d...|2022-04-08|      2016|936923|       4|        3|       3167|   11733|     2|         1|  76|2022|\n",
            "|7530a2d8-1ae3-451...|2021-06-13|      2013|379628|       2|        2|       2235|   14384|     1|         0|  23|2021|\n",
            "|43de979c-0bf0-4c9...|2019-04-12|      2014|417866|       2|        2|       2127|   10575|     2|         0|   0|2019|\n",
            "|b672c137-b88c-48b...|2019-10-16|      2016|239895|       2|        2|       1631|   11149|     2|         0|   0|2019|\n",
            "|e0726d4d-d595-407...|2022-01-08|      2017|424418|       3|        2|       2249|   13878|     2|         0|   4|2022|\n",
            "|5aa00529-0533-46b...|2019-01-30|      2017|218712|       2|        3|       1965|   14375|     2|         0|   7|2019|\n",
            "|131492a1-72e2-4a8...|2020-02-08|      2017|419199|       2|        3|       2062|    8876|     2|         0|   6|2020|\n",
            "|8d54a71b-c520-44e...|2019-07-21|      2010|323956|       2|        3|       1506|   11816|     1|         0|  25|2019|\n",
            "|e81aacfe-17fe-46b...|2020-06-16|      2016|181925|       3|        3|       2137|   11709|     2|         0|  22|2020|\n",
            "|2ed8d509-7372-46d...|2021-08-06|      2015|258710|       3|        3|       1918|    9666|     1|         0|  25|2021|\n",
            "|f876d86f-3c9f-42b...|2019-02-27|      2011|167864|       3|        3|       2471|   13924|     2|         0|  15|2019|\n",
            "|0a2bd445-8508-4d8...|2021-12-30|      2014|337527|       2|        3|       1926|   12556|     1|         0|  23|2021|\n",
            "|941bad30-eb49-4a7...|2020-05-09|      2015|229896|       3|        3|       2197|    8641|     1|         0|   3|2020|\n",
            "|dd61eb34-6589-4c0...|2021-07-25|      2016|210247|       3|        2|       1672|   11986|     2|         0|  28|2021|\n",
            "|f1e4cef7-d151-439...|2019-02-01|      2011|398667|       2|        3|       2331|   11356|     1|         0|   7|2019|\n",
            "|ea620c7b-c2f7-4c6...|2021-05-31|      2011|437958|       3|        3|       2356|   11052|     1|         0|  26|2021|\n",
            "|f233cb41-6f33-4b0...|2021-07-18|      2016|437375|       4|        3|       1704|   11721|     2|         0|  34|2021|\n",
            "|c797ca12-52cd-4b1...|2019-06-08|      2015|288650|       2|        3|       2100|   10419|     2|         0|   7|2019|\n",
            "|0cfe57f3-28c2-472...|2019-10-04|      2015|308313|       3|        3|       1960|    9453|     2|         0|   2|2019|\n",
            "|4566cd2a-ac6e-435...|2019-07-15|      2016|177541|       3|        3|       2130|   10517|     2|         0|  25|2019|\n",
            "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Check if the table is cached.\n",
        "spark.catalog.isCached('home_sales')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWChRB9H2khI",
        "outputId": "f0f719e3-5e9f-4ab0-b244-3b8fd945eced"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Partition by the \"date_built\" field on the formatted parquet home sales data\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df_homesales = spark.read.csv(SparkFiles.get(\"home_sales_revised.csv\"), sep = \",\", header=True)\n",
        "df_homesales.write.parquet(\"/filestore/data/hsp\", mode = \"overwrite\", partitionBy='date_built')\n",
        "# this command above to write a parquet file created a folder called hsp  with datebuilt partion file stored in it.\n",
        "# not sure how to add the folder to github. it is not downloadable. copy path shows /content/hsp"
      ],
      "metadata": {
        "id": "ZzcdYbMMztkL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Read the formatted parquet data\n",
        "homesales_new = spark.read.parquet('/filestore/data/hsp')\n"
      ],
      "metadata": {
        "id": "xw8hGZJRz5vL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Create a temporary table for the parquet data.\n",
        "homesales_new.createOrReplaceTempView('date_built_new')"
      ],
      "metadata": {
        "id": "MKUG68ZSzkME"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "spark.sql(\"\"\"select * from date_built_new \"\"\").show()\n",
        "print(\"----%s seconds -----\" % (time.time() - start_time))\n"
      ],
      "metadata": {
        "id": "4-NmDZZX0NGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91039483-939b-44db-d9d2-69209a991353"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
            "|                  id|      date| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|date_built|\n",
            "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
            "|2ed8d509-7372-46d...|2021-08-06|258710|       3|        3|       1918|    9666|     1|         0|  25|      2015|\n",
            "|941bad30-eb49-4a7...|2020-05-09|229896|       3|        3|       2197|    8641|     1|         0|   3|      2015|\n",
            "|c797ca12-52cd-4b1...|2019-06-08|288650|       2|        3|       2100|   10419|     2|         0|   7|      2015|\n",
            "|0cfe57f3-28c2-472...|2019-10-04|308313|       3|        3|       1960|    9453|     2|         0|   2|      2015|\n",
            "|d715f295-2fbf-4e9...|2021-05-17|391574|       3|        2|       1635|    8040|     2|         0|  10|      2015|\n",
            "|a18515a2-86f3-46b...|2022-02-18|419543|       3|        2|       1642|   12826|     2|         0|  24|      2015|\n",
            "|98f6a9ad-8870-474...|2022-05-07|136752|       2|        3|       1701|   10771|     2|         0|   5|      2015|\n",
            "|7ac67498-b6f3-403...|2021-05-12|349318|       4|        3|       2417|   11304|     2|         0|  37|      2015|\n",
            "|c9bfdb1c-2499-4e3...|2021-12-07|268874|       2|        2|       1537|   12177|     1|         0|  10|      2015|\n",
            "|34c31a34-220d-469...|2019-02-06|409011|       3|        3|       2356|   10507|     1|         0|   1|      2015|\n",
            "|be0ccb95-415d-411...|2020-05-15|425154|       4|        3|       2120|   14229|     2|         0|   4|      2015|\n",
            "|e9031a86-1294-444...|2021-10-09|222322|       4|        3|       1928|   10510|     1|         0|  38|      2015|\n",
            "|e6d7c2a7-596e-4ec...|2019-03-15|131201|       4|        3|       1633|   14655|     1|         0|  22|      2015|\n",
            "|6683714b-3df7-454...|2022-02-01|333403|       4|        2|       2059|    9793|     2|         0|   4|      2015|\n",
            "|00fc996f-508c-430...|2021-07-15|373139|       3|        3|       1763|   11363|     1|         0|  39|      2015|\n",
            "|3d5545f8-bd3b-476...|2020-09-19|797862|       4|        6|       3494|   10385|     2|         0|  90|      2015|\n",
            "|ec6d357c-2435-43e...|2019-05-28|401792|       3|        2|       1627|   10765|     1|         0|  50|      2015|\n",
            "|c2be38fb-814a-403...|2020-03-20|352237|       3|        3|       2485|   10954|     2|         0|   6|      2015|\n",
            "|9570de1f-5a74-45b...|2021-11-29|298453|       3|        2|       2222|   10634|     1|         0|   6|      2015|\n",
            "|1baeff4f-fc00-489...|2020-12-17|152775|       3|        2|       1623|   13851|     1|         0|  41|      2015|\n",
            "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "----0.4109373092651367 seconds -----\n"
          ]
        }
      ]
    }
  ]
}